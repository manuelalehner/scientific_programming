{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #07-01: Using ChatGPT for programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": true
   },
   "source": [
    "A [Galton Board](https://en.wikipedia.org/wiki/Galton_board) is a vertical board with staggered rows of pins or other obstacles. As beads are dropped from the top, they bounce off these pins, either to the left or right, finding a path between the pins until they drop into one of the collecting bins at the bottom. The resulting distribution of beads in the bins will follow a binomial distribution.\n",
    "\n",
    "In this exercise, we are going to explore how we can use [ChatGPT](https://chat.openai.com) to potentially improve our program and our programming style and what some of the drawbacks may be. To interact with ChatGPT, you will need to create an account if you don't have one yet.\n",
    "\n",
    "**A.** Write a program that simulates a Galton Board using only the standard library. The user should be able to specify the number of rows of pins on the Galton Board and the number of beads to simulate as commond-line arguments. For this assignment you are asked to use the [argparse](https://docs.python.org/3/library/argparse.html) module to parse the command-line arguments. The end result of your program should be a list containing the number of beads in each bin. *It is important that you write this code yourself without the help of ChatGPT.*\n",
    "\n",
    "**B.** Now ask ChatGPT to document the code for you. Does it provide accurate and sufficient documentation (e.g., docstrings and meaningful comment lines)?\n",
    "\n",
    "**C.** Ask ChatGPT to provide some suggestions on how to improve your code. But make sure that it still follows the instructions in our assignment. Are the suggestions actually improvements?\n",
    "\n",
    "**C1.** Hit regenerate and see if you get different suggestions this time.\n",
    "\n",
    "**D.** We have not covered plotting yet in our course. So ask ChatGPT to write a function for you to plot the distribution of beads using matplotlib. It should also modify your program accordingly, i.e., include calls to the plot function and store the resulting plot in a directory that the user can specify via command-line arguments. Does the code work as expected?\n",
    "\n",
    "**E.** Now start a fresh conversation with ChatGPT and actually ask it to produce the entire code for you. Is the code doing what it is supposed to be doing? How does it compare to your code? Think about what it takes to make sure that you can rely on the code being correct.\n",
    "\n",
    "**F.** Which of the above interactions with ChatGPT provided useful input to you, which did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #07-02: ACINN meteorological data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will give you a glimpse of working with [pandas](https://pandas.pydata.org/). We are going to analyze a dataset downloaded from the [ACINN department database](https://acinn-data.uibk.ac.at/). The one-month long dataset is from the automatic weather station [TAWES UIBK](https://acinn-data.uibk.ac.at/pages/tawes-uibk.html). [Here](https://acinn-data.uibk.ac.at/station/1/RAWDATA/) you can find a description of the variable names.\n",
    "\n",
    "The data is shared by ACINN under a [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).\n",
    "\n",
    "<a href=\"https://creativecommons.org/licenses/by-sa/4.0/\" target=\"_blank\">\n",
    "  <img src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\"/>\n",
    "</a>\n",
    "\n",
    "You can access the dataset at the URL shown below. Data downloaded from the department database are formatted as [csv](https://en.wikipedia.org/wiki/Comma-separated_values) files, which we can read in easily using pandas. You may want to read the documentation of [read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) to see what all the arguments do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/manuelalehner/scientific_programming/master/data/data_Ibk_Sep2023.csv'\n",
    "# Parse the given url\n",
    "req = urlopen(Request(url)).read()\n",
    "# Read the data\n",
    "data = pd.read_csv(BytesIO(req), sep=';', header=1, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are read into a so-called [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html), which can be very useful for time series analysis, e.g., from weather stations. Let's explore this DataFrame somewhat to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tl', 'tl2', 'ts', 'tb1', 'tb2', 'tb3', 'tp', 'rf', 'rf2', 'rr', 'rrm',\n",
       "       'p', 'som', 'glom', 'ffamm', 'ffm', 'ddm', 'ffxm', 'ddxm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns # list all the column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rawdate\n",
       "2023-09-01 00:00:00    0.0\n",
       "2023-09-01 00:01:00    0.0\n",
       "2023-09-01 00:02:00    0.0\n",
       "2023-09-01 00:03:00    0.0\n",
       "2023-09-01 00:04:00    0.0\n",
       "                      ... \n",
       "2023-09-30 23:55:00    0.0\n",
       "2023-09-30 23:56:00    0.0\n",
       "2023-09-30 23:57:00    0.0\n",
       "2023-09-30 23:58:00    0.0\n",
       "2023-09-30 23:59:00    0.0\n",
       "Name: som, Length: 37434, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['som'] # access the data column 'som' (sunshine duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-09-01 00:00:00', '2023-09-01 00:01:00',\n",
       "               '2023-09-01 00:02:00', '2023-09-01 00:03:00',\n",
       "               '2023-09-01 00:04:00', '2023-09-01 00:05:00',\n",
       "               '2023-09-01 00:06:00', '2023-09-01 00:07:00',\n",
       "               '2023-09-01 00:08:00', '2023-09-01 00:09:00',\n",
       "               ...\n",
       "               '2023-09-30 23:50:00', '2023-09-30 23:51:00',\n",
       "               '2023-09-30 23:52:00', '2023-09-30 23:53:00',\n",
       "               '2023-09-30 23:54:00', '2023-09-30 23:55:00',\n",
       "               '2023-09-30 23:56:00', '2023-09-30 23:57:00',\n",
       "               '2023-09-30 23:58:00', '2023-09-30 23:59:00'],\n",
       "              dtype='datetime64[ns]', name='rawdate', length=37434, freq=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index # access the datetime index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a script that allows the user to input the variable (e.g., air temperature, wind speed, ...) either as a command line argument or using ``input()`` and prints the following information in the terminal.**\n",
    "\n",
    "If the variable is wind direction:\n",
    "\n",
    "    The dominant wind direction was {XX} ({XX}% of the time). The least dominant wind direction was {XX} ({XX}% of the time).\n",
    "    \n",
    "If it is any other variable:\n",
    "\n",
    "    The maximum {VARIABLE} was {XX} {UNITS} ({DATE/TIME}), while the strongest {VARIABLE} averaged over an hour was {XX} {UNITS} ({DATE/TIME}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint 1:* You can use either numpy to determine, for example, the maximum values or you can work directly with the DataFrame. ([e.g., calculating the maximum](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html)). To convert a column of the DataFrame to a numpy array, you can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data['som'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint 2:* Calculating time averages is easy using the pandas [resample](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html) method.\n",
    "\n",
    "*Hint 3:* For wind direction, use the following eight wind direction classes: N, NW, W, SW, S, SE, E, NE.\n",
    "\n",
    "*Hint 4:* To output the datetime index in a specific format, you can use the [strftime](https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.strftime.html) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #04-02: Reading and writing netCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[netCDF](https://www.unidata.ucar.edu/software/netcdf/) is a very commonly used data format in the Atmospheric Sciences and it is becoming more and more of a standard for data exchange because netCDF data files are self-describing. That means that the format allows you to store metadata (e.g., information about the measurement location and instrumentation and information about each of the variables) together with the actual data.\n",
    "\n",
    "It is thus not unlikely that you will encounter netCDF data during your studies, e.g., output from the WRF model, such as this [file](https://fileshare.uibk.ac.at/f/82dfc813aa0b4bc8bf33/?dl=1). In this exercise, we are going get some experience with the netCDF file structure. Unlike our WRF output file, which contains only a small subset of variables, full model output files can be very large. To share data with other people, you may thus want to split the file into multiple smaller files or extract only part of the data.\n",
    "\n",
    "You will need to install the [netCDF4 package](https://unidata.github.io/netcdf4-python/) for this exercise and you should read the sections on creating/opening/closing, dimensions, variables, and attributes of the documentation to get familiar with the structure of netcdf files.\n",
    "\n",
    "**A.** Write a program that creates a new netcdf file for each of the variables in the original file (use the netcdf4 format).\n",
    "\n",
    "*Hint A1:* The dimensions and the global attributes will be the same for each of the new files. You can copy them directly from the original file, that is, read them from the original file and create the corresponding dimension/attribute in the new dataset.\n",
    "\n",
    "*Hint A2:* The data are either one- or two-dimensional arrays similar to ``numpy`` arrays, which we will only introduce in the next chapter. Here, you simply need to copy the whole array to the new dataset, e.g.,\n",
    "```python\n",
    "# example for variable TSK\n",
    "# nc0 ... original dataset created with nc.Dataset()\n",
    "# nc1 ... new dataset\n",
    "temp = nc1.createVariable('TSK', nc0['TSK'].dtype, nc0['TSK'].dimensions)\n",
    "temp[:] = nc0['TSK'][:]\n",
    "```\n",
    "\n",
    "*Hint A3:* Each of the variables contains also its own attributes, which you need to copy to the new datasets together with the data.\n",
    "\n",
    "\n",
    "**B. (optional)** Add the option of writing a new netcdf file for each output time instead of each variable, that is, each of the new files contains all the variables, but only for a single output time.\n",
    "\n",
    "*Hint B1:* Add a command-line option that allows the user to choose between writing files for each variable or files for each output time.\n",
    "\n",
    "*Hint B2:* Since each of the new files will contain only a single output time, the dimension 'Time' should be removed.\n",
    "\n",
    "*Hint B3:* If one of the dimensions of a variable is 'Time', you need to extract the data for a given output time from the data arrays. Here is an example for variable 'TSK':\n",
    "```python\n",
    "# example for variable TSK and the output time with the index 'it'\n",
    "data = nc0['TSK'][:]\n",
    "# create indeces that cover the whole array\n",
    "ind = [slice(0, dimlen) for dimlen in data.shape]\n",
    "# since we don't know in advance which dimension is Time, we need to first find out from the list of dimensions\n",
    "dims = list(nc0['TSK'].dimensions)\n",
    "timeind = dims.index('Time')\n",
    "# now we can replace the slice for the time dimension with the single index of the selected output time\n",
    "ind[timeind] = it\n",
    "data = data[tuple(ind)]\n",
    "```\n",
    "Here we are making use of so-called [list comprehensions](https://docs.python.org/2/tutorial/datastructures.html#list-comprehensions) to create the indeces ``ind``. *Remember to also remove 'Time' from the variable dimensions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
